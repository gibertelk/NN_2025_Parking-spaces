{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7674d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –ø–∞–ø–∫–∏ train –∏ valid —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –∞–Ω–æ—Ç–∞—Ü–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å —ç–º–±–µ–¥–∏–Ω–≥–æ–º\n",
    "# –ü–∞–ø–∫–∞ test –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –æ—Ç–¥–µ–ª—å–Ω–æ, –∏–∑ —Ñ–∞–π–ª–æ–≤ –ø–∞–ø–∫–∏ test –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "(train_dir := data_dir / \"train\").mkdir(exist_ok=True)\n",
    "(valid_dir := data_dir / \"valid\").mkdir(exist_ok=True)\n",
    "(train_images_dir := train_dir / \"images\").mkdir(exist_ok=True)\n",
    "(valid_images_dir := valid_dir / \"images\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102c810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 1676\n",
      "   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: 3\n",
      "   –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: 96248\n"
     ]
    }
   ],
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç\n",
    "class Dataset1(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n",
    "        anno_path = self.root_dir / \"_annotations.coco.json\"\n",
    "        with open(anno_path, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        \n",
    "        self.image_id_to_info = {img['id']: img for img in self.coco_data['images']}\n",
    "        self.category_id_to_name = {cat['id']: cat['name'] for cat in self.coco_data['categories']}\n",
    "        \n",
    "        self.image_id_to_annotations = defaultdict(list)\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            self.image_id_to_annotations[ann['image_id']].append(ann)\n",
    "        \n",
    "        self.image_ids = list(self.image_id_to_info.keys())\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "        self.image_paths = []\n",
    "        for img_id in self.image_ids:\n",
    "            img_info = self.image_id_to_info[img_id]\n",
    "            self.image_paths.append(self.root_dir / img_info['file_name'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image_id = self.image_ids[idx]\n",
    "        \n",
    "        try:\n",
    "            image = read_image(str(img_path)).float() / 255.0\n",
    "        except:\n",
    "            from PIL import Image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            image = transforms.ToTensor()(img)\n",
    "        \n",
    "        annotations = self.image_id_to_annotations[image_id]\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for ann in annotations:\n",
    "            # [x_min, y_min, width, height]\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann['category_id'])\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, {\n",
    "            'image_id': image_id,\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'annotations': annotations}\n",
    "    \n",
    "    def get_image_info(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        return self.image_id_to_info[image_id]\n",
    "    \n",
    "    def get_all_image_infos(self):\n",
    "        return [self.image_id_to_info[img_id] for img_id in self.image_ids]\n",
    "\n",
    "\n",
    "stratified_dir = Path(\"stratified_15percent\")\n",
    "dataset = Dataset1(stratified_dir)\n",
    "\n",
    "print(f\"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(dataset)}\")\n",
    "print(f\"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(dataset.coco_data['categories'])}\")\n",
    "print(f\"   –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: {len(dataset.coco_data['annotations'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f58107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n",
      "–ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –¥–ª—è 1676 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210/210 [12:49<00:00,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–∑–≤–ª–µ—á–µ–Ω–æ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: (1676, 512)\n",
      "–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–∞: 512\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\n",
    "def extract_embeddings_from_dataset(dataset, batch_size=8):\n",
    "    print(\"üß† –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\")\n",
    "    \n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π ResNet18\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    resnet = resnet.to(device)\n",
    "    resnet.eval()\n",
    "    \n",
    "    feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "    feature_extractor = feature_extractor.to(device)\n",
    "    \n",
    "    def extract_batch_embeddings(images):\n",
    "        with torch.no_grad():\n",
    "            if images.dim() == 3:\n",
    "                images = images.unsqueeze(0)\n",
    "            \n",
    "            normalize = transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "            images = normalize(images)\n",
    "            \n",
    "            x = feature_extractor(images)  # [B, 512, 1, 1]\n",
    "            x = x.view(x.size(0), -1)      # [B, 512]\n",
    "        return x\n",
    "    \n",
    "    all_embeddings = []\n",
    "    all_indices = []\n",
    "    \n",
    "    print(f\"–ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –¥–ª—è {len(dataset)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...\")\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤\"):\n",
    "        batch_indices = list(range(i, min(i + batch_size, len(dataset))))\n",
    "        batch_images = []\n",
    "        \n",
    "        for idx in batch_indices:\n",
    "            image, _ = dataset[idx]\n",
    "            batch_images.append(image)\n",
    "        \n",
    "        if not batch_images:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            batch_tensor = torch.stack(batch_images).to(device)\n",
    "            \n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–±–µ–¥–∏–Ω–≥–∏\n",
    "            embeddings = extract_batch_embeddings(batch_tensor)\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            all_indices.extend(batch_indices)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
    "    \n",
    "    print(f\"–ò–∑–≤–ª–µ—á–µ–Ω–æ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤: {all_embeddings.shape}\")\n",
    "    print(f\"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–∞: {all_embeddings.shape[1]}\")\n",
    "    print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_indices)}\")\n",
    "    \n",
    "    return all_embeddings, all_indices\n",
    "\n",
    "embeddings, indices = extract_embeddings_from_dataset(dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de994a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º 10 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 0: 190 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 1: 88 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 2: 193 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 3: 190 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 4: 228 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 5: 142 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 6: 185 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 7: 287 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 8: 93 –æ–±—Ä–∞–∑—Ü–æ–≤\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 9: 80 –æ–±—Ä–∞–∑—Ü–æ–≤\n"
     ]
    }
   ],
   "source": [
    "# K-means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è\n",
    "def cluster_embeddings(embeddings):\n",
    "    \n",
    "    n_clusters = min(10, len(embeddings) // 20)\n",
    "    n_clusters = max(2, n_clusters)\n",
    "    \n",
    "    print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\")\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    cluster_counts = Counter(cluster_labels)\n",
    "    print(f\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:\")\n",
    "    for cluster_id in range(n_clusters):\n",
    "        count = cluster_counts.get(cluster_id, 0)\n",
    "        percentage = count / len(cluster_labels) * 100\n",
    "        print(f\"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count} –æ–±—Ä–∞–∑—Ü–æ–≤\")\n",
    "    \n",
    "    return cluster_labels, n_clusters\n",
    "\n",
    "cluster_labels, n_clusters = cluster_embeddings(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e26dfbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 1508 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "Valid: 168 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:\n",
      "Train:\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 0: 171 (11.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 1: 79 (5.2%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 2: 174 (11.5%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 3: 171 (11.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 4: 205 (13.6%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 5: 128 (8.5%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 6: 166 (11.0%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 7: 258 (17.1%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 8: 84 (5.6%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 9: 72 (4.8%)\n",
      "\n",
      "Valid:\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 0: 19 (11.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 1: 9 (5.4%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 2: 19 (11.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 3: 19 (11.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 4: 23 (13.7%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 5: 14 (8.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 6: 19 (11.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 7: 29 (17.3%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 8: 9 (5.4%)\n",
      "–ö–ª–∞—Å—Ç–µ—Ä 9: 8 (4.8%)\n"
     ]
    }
   ],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/valid\n",
    "def stratified_split_by_clusters(indices, cluster_labels, test_size=0.1, random_state=42):\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1, \n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_indices = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for train_idx, valid_idx in sss.split(indices, cluster_labels):\n",
    "        train_indices = [indices[i] for i in train_idx]\n",
    "        valid_indices = [indices[i] for i in valid_idx]\n",
    "    \n",
    "    print()\n",
    "    print(f\"Train: {len(train_indices)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "    print(f\"Valid: {len(valid_indices)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\")\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n",
    "    print(f\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:\")\n",
    "    \n",
    "    idx_to_cluster = {idx: cluster for idx, cluster in zip(indices, cluster_labels)}\n",
    "    \n",
    "    # Train —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "    train_clusters = [idx_to_cluster[idx] for idx in train_indices]\n",
    "    train_cluster_counts = Counter(train_clusters)\n",
    "    \n",
    "    print(f\"Train:\")\n",
    "    for cluster_id in range(n_clusters):\n",
    "        count = train_cluster_counts.get(cluster_id, 0)\n",
    "        percentage = count / len(train_indices) * 100 if train_indices else 0\n",
    "        print(f\"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Valid —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "    valid_clusters = [idx_to_cluster[idx] for idx in valid_indices]\n",
    "    valid_cluster_counts = Counter(valid_clusters)\n",
    "    \n",
    "    print()\n",
    "    print(f\"Valid:\")\n",
    "    for cluster_id in range(n_clusters):\n",
    "        count = valid_cluster_counts.get(cluster_id, 0)\n",
    "        percentage = count / len(valid_indices) * 100 if valid_indices else 0\n",
    "        print(f\"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return train_indices, valid_indices\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train –∏ valid\n",
    "train_indices, valid_indices = stratified_split_by_clusters(\n",
    "    indices=indices,\n",
    "    cluster_labels=cluster_labels,\n",
    "    test_size=0.1,  # 10% –¥–ª—è valid\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb7fa478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1508/1508 [00:13<00:00, 115.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 1508\n",
      "–ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: 86508\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 168/168 [00:02<00:00, 62.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 168\n",
      "–ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: 9740\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–ø–∫–∏\n",
    "def save_dataset(dataset, indices, output_dir, split_name):\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É COCO JSON\n",
    "    coco_output = {\n",
    "        \"info\": { },\n",
    "        \"licenses\": [],\n",
    "        \"categories\": dataset.coco_data[\"categories\"],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [] }\n",
    "    \n",
    "    new_image_id = 1\n",
    "    new_annotation_id = 1\n",
    "    old_to_new_image_id = {}\n",
    "    \n",
    "    for idx in tqdm(indices):\n",
    "        try:\n",
    "            img_info = dataset.get_image_info(idx)\n",
    "            original_image_id = img_info['id']\n",
    "            \n",
    "            original_image_path = dataset.image_paths[idx]\n",
    "            \n",
    "            new_image_filename = f\"{split_name}_{new_image_id:06d}{original_image_path.suffix}\"\n",
    "            new_image_path = output_dir / new_image_filename\n",
    "            \n",
    "            shutil.copy2(original_image_path, new_image_path)\n",
    "            \n",
    "            new_image_info = {\n",
    "                \"id\": new_image_id,\n",
    "                \"file_name\": new_image_filename,\n",
    "                \"width\": img_info['width'],\n",
    "                \"height\": img_info['height'],\n",
    "                \"original_id\": original_image_id,\n",
    "                \"original_filename\": img_info['file_name']}\n",
    "            coco_output[\"images\"].append(new_image_info)\n",
    "            \n",
    "            old_to_new_image_id[original_image_id] = new_image_id\n",
    "            \n",
    "            # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "            annotations = dataset.image_id_to_annotations.get(original_image_id, [])\n",
    "            \n",
    "            for ann in annotations:\n",
    "                new_annotation = {\n",
    "                    \"id\": new_annotation_id,\n",
    "                    \"image_id\": new_image_id,\n",
    "                    \"category_id\": ann['category_id'],\n",
    "                    \"bbox\": ann['bbox'],\n",
    "                    \"area\": ann['area'],\n",
    "                    \"segmentation\": ann.get('segmentation', []),\n",
    "                    \"iscrowd\": ann.get('iscrowd', 0),\n",
    "                    \"original_id\": ann['id'] }\n",
    "                coco_output[\"annotations\"].append(new_annotation)\n",
    "                new_annotation_id += 1\n",
    "            \n",
    "            new_image_id += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    annotations_path = output_dir / \"_annotations.coco.json\"\n",
    "    with open(annotations_path, 'w') as f:\n",
    "        json.dump(coco_output, f, indent=2)\n",
    "    \n",
    "    print(f\"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(coco_output['images'])}\")\n",
    "    print(f\"–ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: {len(coco_output['annotations'])}\")\n",
    "    \n",
    "    return coco_output\n",
    "\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º train\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ train\")\n",
    "train_coco = save_dataset(\n",
    "    dataset=dataset,\n",
    "    indices=train_indices,\n",
    "    output_dir=train_dir,\n",
    "    split_name=\"train\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º valid\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ val\")\n",
    "valid_coco = save_dataset(\n",
    "    dataset=dataset,\n",
    "    indices=valid_indices,\n",
    "    output_dir=valid_dir,\n",
    "    split_name=\"valid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
